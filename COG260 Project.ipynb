{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90f41e36-7e1a-4e14-85d1-f826983eb35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WCS data...\n",
      "Loaded 30991 points, 832 terms.\n",
      "\n",
      "=== Running KMEANS (English anchors) ===\n",
      "Hypothesis test: {'Early_Mean': np.float64(13.882471690259361), 'Late_Mean': np.float64(24.520019498609074), 'Hypothesis_Result': 'Late terms more dispersed'}\n",
      "\n",
      "=== Running GMM (English anchors) ===\n",
      "Hypothesis test: {'Early_Mean': np.float64(11.471797665650733), 'Late_Mean': np.float64(21.734782300280287), 'Hypothesis_Result': 'Late terms more dispersed'}\n",
      "\n",
      "=== Running KMEANS (Munsell anchors) ===\n",
      "Hypothesis test: {'Early_Mean': np.float64(13.882471690259361), 'Late_Mean': np.float64(24.520019498609074), 'Hypothesis_Result': 'Late terms more dispersed'}\n",
      "\n",
      "=== Running GMM (Munsell anchors) ===\n",
      "Hypothesis test: {'Early_Mean': np.float64(12.210454229880531), 'Late_Mean': np.float64(21.734782300280287), 'Hypothesis_Result': 'Late terms more dispersed'}\n",
      "\n",
      "All analyses complete. Final summary table saved as 'results/final_hypothesis_summary.csv'.\n",
      "\n",
      "Generated plots saved at:\n",
      "results/kmeans_english_stage_violin.png\n",
      "results/kmeans_english_cat_means_color.png\n",
      "results/gmm_english_stage_violin.png\n",
      "results/gmm_english_cat_means_color.png\n",
      "results/kmeans_munsell_stage_violin.png\n",
      "results/kmeans_munsell_cat_means_color.png\n",
      "results/gmm_munsell_stage_violin.png\n",
      "results/gmm_munsell_cat_means_color.png\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# IMPORTS\n",
    "# ===================================================\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Custom helper functions to read WCS experiment data\n",
    "from wcs_helper_functions import readFociData, readClabData, readChipData\n",
    "\n",
    "# ===================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ===================================================\n",
    "NUM_CLUSTERS = 11                # Number of clusters for KMeans/GMM\n",
    "MIN_SPEAKER_CONSENSUS = 10       # Minimum number of speakers required for a term\n",
    "PERMUTATION_ITERS = 5000         # Number of iterations for permutation test\n",
    "RANDOM_STATE = 42                # Random seed for reproducibility\n",
    "\n",
    "# Names of the 11 anchor colors\n",
    "ANCHOR_NAMES = ['BLACK','WHITE','RED','GREEN','YELLOW','BLUE','BROWN','PURPLE','PINK','ORANGE','GREY']\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# English WCS anchors (with LAB coordinates and evolutionary stage)\n",
    "English_ANCHORS = {\n",
    "    'BLACK':  {'coord': [5.00,0.00,0.00],  'Stage': 1},\n",
    "    'WHITE':  {'coord': [95.00,0.00,0.00], 'Stage': 1},\n",
    "    'RED':    {'coord': [39.7,44.84,10.02], 'Stage': 2},\n",
    "    'GREEN':  {'coord': [53.5,-32.64,18.67], 'Stage': 3},\n",
    "    'YELLOW': {'coord': [75.6,6.45,40.89],   'Stage': 3},\n",
    "    'BLUE':   {'coord': [54.2,-10.26,-23.46], 'Stage': 4},\n",
    "    'BROWN':  {'coord': [44.1,14.57,17.28],   'Stage': 5},\n",
    "    'PURPLE': {'coord': [45.3,17.1,-19.72],   'Stage': 6},\n",
    "    'PINK':   {'coord': [60.4,28.17,3.63],    'Stage': 6},\n",
    "    'ORANGE': {'coord': [59.1,37.39,33.94],   'Stage': 6},\n",
    "    'GREY':   {'coord': [54.0,-0.88,1.22],    'Stage': 6},\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# Munsell anchors (alternative color system)\n",
    "MUNSELL_ANCHORS = {\n",
    "    'BLACK': {'coord':[5,0,0], 'Stage':1},\n",
    "    'WHITE': {'coord':[95,0,0], 'Stage':1},\n",
    "    'RED': {'coord':[45,68,40], 'Stage':2},\n",
    "    'GREEN': {'coord':[50,-60,40], 'Stage':3},\n",
    "    'YELLOW': {'coord':[85,-5,85], 'Stage':3},\n",
    "    'BLUE': {'coord':[38,12,-48], 'Stage':4},\n",
    "    'BROWN': {'coord':[35,18,30], 'Stage':5},\n",
    "    'PURPLE': {'coord':[40,45,-30], 'Stage':6},\n",
    "    'PINK': {'coord':[75,35,10], 'Stage':6},\n",
    "    'ORANGE': {'coord':[65,45,55], 'Stage':6},\n",
    "    'GREY': {'coord':[50,0,0], 'Stage':6}\n",
    "}\n",
    "\n",
    "# Predefined colors for plotting bars\n",
    "ANCHOR_COLORS = {\n",
    "    'BLACK':'black',\n",
    "    'WHITE':'lightgrey',\n",
    "    'RED':'red',\n",
    "    'GREEN':'green',\n",
    "    'YELLOW':'yellow',\n",
    "    'BLUE':'blue',\n",
    "    'BROWN':'saddlebrown',\n",
    "    'PURPLE':'purple',\n",
    "    'PINK':'deeppink',\n",
    "    'ORANGE':'orange',\n",
    "    'GREY':'grey'\n",
    "}\n",
    "\n",
    "# ===================================================\n",
    "# DISTANCE FUNCTION\n",
    "# ===================================================\n",
    "def delta_e_lab(a, b):\n",
    "    \"\"\"\n",
    "    Compute Euclidean distance (Delta E) between two LAB points.\n",
    "    \n",
    "    Parameters:\n",
    "    a, b : list or array\n",
    "        LAB coordinates\n",
    "    \n",
    "    Returns:\n",
    "    float : Euclidean distance\n",
    "    \"\"\"\n",
    "    a = np.asarray(a, float)\n",
    "    b = np.asarray(b, float)\n",
    "    return float(np.linalg.norm(a - b))\n",
    "\n",
    "# ===================================================\n",
    "# DATA LOADING\n",
    "# ===================================================\n",
    "def load_and_prep_data(path=\"./WCS_data_core\"):\n",
    "    \"\"\"\n",
    "    Load WCS experiment data and prepare a cleaned term database.\n",
    "\n",
    "    Returns:\n",
    "    - all_pts: list of all LAB points\n",
    "    - term_db: list of dicts, each containing term info and coordinates\n",
    "    \"\"\"\n",
    "    # Load foci (speaker term coordinates), clab (chip→LAB mapping), and chip info\n",
    "    foci = readFociData(os.path.join(path,\"foci-exp.txt\"))\n",
    "    clab = readClabData(os.path.join(path,\"cnum-vhcm-lab-new.txt\"))\n",
    "    chip = readChipData(os.path.join(path,\"chip.txt\"))[0]\n",
    "\n",
    "    all_pts = []\n",
    "    term_db = []\n",
    "\n",
    "    # Iterate over languages and speakers\n",
    "    for lang, speakers in foci.items():\n",
    "        term_map = {}\n",
    "        for spk, terms in speakers.items():\n",
    "            for t, fociList in terms.items():\n",
    "                term_map.setdefault(t, [])\n",
    "                for f in fociList:\n",
    "                    code = f.replace(\":\",\"\")\n",
    "                    if code in chip and chip[code] in clab:\n",
    "                        L,a,b = clab[chip[code]]\n",
    "                        try:\n",
    "                            pt = [float(L),float(a),float(b)]\n",
    "                        except:\n",
    "                            continue\n",
    "                        term_map[t].append(pt)\n",
    "                        all_pts.append(pt)\n",
    "\n",
    "        # Filter terms by minimum speaker consensus\n",
    "        for term, coords in term_map.items():\n",
    "            if len(coords) >= MIN_SPEAKER_CONSENSUS:\n",
    "                term_db.append({\n",
    "                    \"Lang_ID\": lang,\n",
    "                    \"Term_Label\": term,\n",
    "                    \"Coords\": np.array(coords)\n",
    "                })\n",
    "\n",
    "    return np.array(all_pts), term_db\n",
    "\n",
    "# ===================================================\n",
    "# CLUSTER → ANCHOR MAPPING\n",
    "# ===================================================\n",
    "def label_clusters_by_anchors(centers, anchor_dict):\n",
    "    \"\"\"\n",
    "    Map each cluster center to the nearest anchor.\n",
    "    \n",
    "    Parameters:\n",
    "    - centers: array of cluster centers\n",
    "    - anchor_dict: dictionary of anchor coordinates\n",
    "    \n",
    "    Returns:\n",
    "    dict mapping cluster IDs to closest anchor info\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for cid, c in enumerate(centers):\n",
    "        best, bestd = None, 1e9\n",
    "        for name, info in anchor_dict.items():\n",
    "            d = delta_e_lab(c, info[\"coord\"])\n",
    "            if d < bestd:\n",
    "                bestd = d\n",
    "                best = (name, info[\"Stage\"])\n",
    "        out[cid] = {\n",
    "            \"Name\": best[0],\n",
    "            \"Stage\": best[1],\n",
    "            \"Anchor_Dist\": float(bestd),\n",
    "            \"Center\": c.tolist()\n",
    "        }\n",
    "    return out\n",
    "\n",
    "# ===================================================\n",
    "# DISPERSION COMPUTATION\n",
    "# ===================================================\n",
    "def compute_term_dispersion(term_db, model, cluster_map):\n",
    "    \"\"\"\n",
    "    Compute mean dispersion (ΔE) of each term from its centroid.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with columns: Lang_ID, Native_Term, Universal_Category, Stage, Variability, nTokens\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for e in term_db:\n",
    "        pts = e[\"Coords\"]\n",
    "        if pts.size == 0:\n",
    "            continue\n",
    "        centroid = pts.mean(axis=0)                 # compute centroid of term\n",
    "        cl = model.predict(centroid.reshape(1,-1))[0]  # cluster assignment\n",
    "        cat = cluster_map[cl][\"Name\"]\n",
    "        stage = cluster_map[cl][\"Stage\"]\n",
    "        dists = [delta_e_lab(p, centroid) for p in pts]  # distances to centroid\n",
    "        rows.append({\n",
    "            \"Lang_ID\": e[\"Lang_ID\"],\n",
    "            \"Native_Term\": e[\"Term_Label\"],\n",
    "            \"Universal_Category\": cat,\n",
    "            \"Stage\": stage,\n",
    "            \"Variability\": float(np.mean(dists)),\n",
    "            \"nTokens\": len(pts)\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ===================================================\n",
    "# PERMUTATION TEST\n",
    "# ===================================================\n",
    "def permutation_test(df, stage_map, iters=5000, seed=42):\n",
    "    \"\"\"\n",
    "    Perform a permutation test for correlation between stage and dispersion.\n",
    "    \n",
    "    Returns:\n",
    "    - observed Spearman correlation\n",
    "    - p-value\n",
    "    - null distribution\n",
    "    \"\"\"\n",
    "    df2 = df.copy()\n",
    "    df2[\"Stage\"] = df2[\"Universal_Category\"].map(stage_map)\n",
    "    stages = df2[\"Stage\"].values.astype(float)\n",
    "    vals = df2[\"Variability\"].values.astype(float)\n",
    "    \n",
    "    # Observed correlation\n",
    "    rho_obs, _ = spearmanr(stages, vals)\n",
    "    \n",
    "    # Null distribution\n",
    "    rng = np.random.default_rng(seed)\n",
    "    null = np.zeros(iters)\n",
    "    for i in range(iters):\n",
    "        perm = rng.permutation(stages)\n",
    "        null[i], _ = spearmanr(perm, vals)\n",
    "    \n",
    "    # Compute permutation p-value\n",
    "    p = np.mean(np.abs(null) >= np.abs(rho_obs))\n",
    "    return float(rho_obs), float(p), null\n",
    "\n",
    "# ===================================================\n",
    "# PLOTTING\n",
    "# ===================================================\n",
    "def make_plots(df, anchors, method_name, anchor_name, prefix):\n",
    "    \"\"\"\n",
    "    Generate violin and bar plots of dispersion.\n",
    "    \n",
    "    Returns: list of saved file paths\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    stage_map = {k: anchors[k][\"Stage\"] for k in anchors}\n",
    "    df = df.copy()\n",
    "    df[\"Stage\"] = df[\"Universal_Category\"].map(stage_map)\n",
    "\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    plot_files = []\n",
    "\n",
    "    # --- Violin plot by evolutionary stage ---\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.violinplot(data=df, x=\"Stage\", y=\"Variability\", inner=\"box\", cut=0)\n",
    "    plt.title(f\"Dispersion by evolutionary stage ({method_name.upper()}, {anchor_name} anchors)\")\n",
    "    plt.xlabel(\"Evolutionary Stage\")\n",
    "    plt.ylabel(\"Mean Dispersion (ΔE)\")\n",
    "    plt.tight_layout()\n",
    "    f1 = f\"{prefix}_stage_violin.png\"\n",
    "    plt.savefig(f1, dpi=200)\n",
    "    plt.close()\n",
    "    plot_files.append(f1)\n",
    "\n",
    "    # --- Category mean barplot ---\n",
    "    cat_means = df.groupby(\"Universal_Category\")[\"Variability\"].mean().reset_index()\n",
    "    cat_means[\"Universal_Category\"] = pd.Categorical(cat_means[\"Universal_Category\"],\n",
    "                                                     categories=ANCHOR_NAMES, ordered=True)\n",
    "    cat_means = cat_means.sort_values(\"Universal_Category\")\n",
    "    colors = [ANCHOR_COLORS[cat] for cat in cat_means[\"Universal_Category\"]]\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.barplot(data=cat_means, x=\"Universal_Category\", y=\"Variability\", palette=colors)\n",
    "    plt.title(f\"Category mean dispersion ({method_name.upper()}, {anchor_name} anchors)\")\n",
    "    plt.xlabel(\"Universal Category\")\n",
    "    plt.ylabel(\"Mean Dispersion (ΔE)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    f2 = f\"{prefix}_cat_means_color.png\"\n",
    "    plt.savefig(f2, dpi=200)\n",
    "    plt.close()\n",
    "    plot_files.append(f2)\n",
    "\n",
    "    return plot_files\n",
    "\n",
    "# ===================================================\n",
    "# HYPOTHESIS TESTING\n",
    "# ===================================================\n",
    "def test_late_vs_early(df):\n",
    "    \"\"\"\n",
    "    Compare mean dispersion of early vs late stage terms.\n",
    "    \n",
    "    Returns a dictionary summarizing the hypothesis result.\n",
    "    \"\"\"\n",
    "    stage_means = df.groupby(\"Stage\")[\"Variability\"].mean()\n",
    "    early_mean = stage_means.loc[stage_means.index<=2].mean()\n",
    "    late_mean  = stage_means.loc[stage_means.index>=5].mean()\n",
    "    hypothesis = \"Late terms more dispersed\" if late_mean > early_mean else \"No support\"\n",
    "    return {\n",
    "        \"Early_Mean\": early_mean,\n",
    "        \"Late_Mean\": late_mean,\n",
    "        \"Hypothesis_Result\": hypothesis\n",
    "    }\n",
    "\n",
    "# ===================================================\n",
    "# MAIN ANALYSIS FUNCTION\n",
    "# ===================================================\n",
    "def run_analysis(X, term_db, anchors, method=\"kmeans\"):\n",
    "    \"\"\"\n",
    "    Run full analysis pipeline:\n",
    "    - Cluster terms (KMeans or GMM)\n",
    "    - Map clusters to anchors\n",
    "    - Compute dispersion\n",
    "    - Perform permutation test\n",
    "    - Generate plots\n",
    "    - Test late vs early hypothesis\n",
    "    - Save results\n",
    "    \"\"\"\n",
    "    anchor_name = \"English\" if anchors is English_ANCHORS else \"Munsell\"\n",
    "    print(f\"\\n=== Running {method.upper()} ({anchor_name} anchors) ===\")\n",
    "\n",
    "    # --- Clustering ---\n",
    "    if method==\"kmeans\":\n",
    "        model = KMeans(n_clusters=NUM_CLUSTERS, random_state=RANDOM_STATE, n_init=10)\n",
    "        model.fit(X)\n",
    "        centers = model.cluster_centers_\n",
    "    else:\n",
    "        model = GaussianMixture(n_components=NUM_CLUSTERS, random_state=RANDOM_STATE)\n",
    "        model.fit(X)\n",
    "        centers = model.means_\n",
    "\n",
    "    # --- Map clusters to nearest anchor ---\n",
    "    cmap = label_clusters_by_anchors(centers, anchors)\n",
    "\n",
    "    # --- Compute term dispersions ---\n",
    "    df = compute_term_dispersion(term_db, model, cmap)\n",
    "\n",
    "    # --- Permutation correlation test ---\n",
    "    stage_map = {name: anchors[name][\"Stage\"] for name in anchors}\n",
    "    rho, p, null = permutation_test(df, stage_map, iters=PERMUTATION_ITERS)\n",
    "\n",
    "    # --- Plotting ---\n",
    "    prefix = f\"results/{method}_{anchor_name.lower()}\"\n",
    "    plot_files = make_plots(df, anchors, method, anchor_name, prefix)\n",
    "\n",
    "    # --- Test hypothesis: late vs early terms ---\n",
    "    hypo = test_late_vs_early(df)\n",
    "    print(f\"Hypothesis test: {hypo}\")\n",
    "\n",
    "    # --- Save results ---\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    df.to_csv(f\"{prefix}_term_dispersion.csv\", index=False)\n",
    "    with open(f\"{prefix}_cluster_map.json\",\"w\") as f: \n",
    "        json.dump(cmap,f,indent=2)\n",
    "    json.dump({\"rho\":rho, \"p_perm\":p, **hypo}, open(f\"{prefix}_summary.json\",\"w\"), indent=2)\n",
    "\n",
    "    summary = {\"rho\":rho, \"p_perm\":p, **hypo}\n",
    "    return df, cmap, summary, plot_files\n",
    "\n",
    "# ===================================================\n",
    "# MAIN ENTRY POINT\n",
    "# ===================================================\n",
    "if __name__==\"__main__\":\n",
    "    print(\"Loading WCS data...\")\n",
    "    X, term_db = load_and_prep_data()\n",
    "    print(f\"Loaded {len(X)} points, {len(term_db)} terms.\")\n",
    "\n",
    "    results = []\n",
    "    all_plots = []\n",
    "\n",
    "    # Run analysis for both anchor sets and both methods\n",
    "    for anchors in [English_ANCHORS, MUNSELL_ANCHORS]:\n",
    "        for method in [\"kmeans\",\"gmm\"]:\n",
    "            df, cmap, summary, plots = run_analysis(X, term_db, anchors, method)\n",
    "            summary[\"Anchor_Set\"] = \"English\" if anchors is English_ANCHORS else \"Munsell\"\n",
    "            summary[\"Method\"] = method\n",
    "            results.append(summary)\n",
    "            all_plots.extend(plots)\n",
    "\n",
    "    # Save final summary table\n",
    "    final_table = pd.DataFrame(results)\n",
    "    final_table = final_table[[\"Anchor_Set\",\"Method\",\"Early_Mean\",\"Late_Mean\",\"Hypothesis_Result\",\"p_perm\"]]\n",
    "    final_table.to_csv(\"results/final_hypothesis_summary.csv\", index=False)\n",
    "    print(\"\\nAll analyses complete. Final summary table saved as 'results/final_hypothesis_summary.csv'.\")\n",
    "\n",
    "    # Print paths to generated plots\n",
    "    print(\"\\nGenerated plots saved at:\")\n",
    "    for p in all_plots:\n",
    "        print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0bb62c-161e-41ad-b8ca-43549ec0d361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
